{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLTK: sentiment analysis.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPHq0ODnMVpNRRYGOJ4AfgX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JGURJ0hV_bp7","colab_type":"text"},"source":["# Natural Language Processing: sentiment analysis"]},{"cell_type":"markdown","metadata":{"id":"XJKZgfTuAQdU","colab_type":"text"},"source":["## Import modules"]},{"cell_type":"code","metadata":{"id":"AVCmXJ9uxask","colab_type":"code","colab":{}},"source":["# import nltk\n","# nltk.download('all')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KtGxar7__Yqo","colab_type":"code","outputId":"2d4f5b3c-3fa4-4679-b058-d6de476d220a","executionInfo":{"status":"ok","timestamp":1591804516276,"user_tz":-120,"elapsed":1269,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["import numpy as np\n","import pandas as pd \n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, sent_tokenize, word_tokenize\n","from nltk.probability import ConditionalFreqDist\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","\n","# For regex filter\n","import re\n","\n","# For bag-of-words\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score, StratifiedKFold\n","from sklearn.metrics import make_scorer,mean_squared_error"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wu_y43W__k_2","colab_type":"text"},"source":["## Mission 1 ✔\n","Crée un compte sur Kaggle, puis télécharge les données à partir de [cette adresse](https://www.kaggle.com/c/tweet-sentiment-extraction/data?select=train.csv). Tu peux aussi les télécharger via l'[API de Kaggle](https://www.kaggle.com/docs/api)."]},{"cell_type":"code","metadata":{"id":"VOK7HHQ9DAyu","colab_type":"code","colab":{}},"source":["url_train = \"https://raw.githubusercontent.com/h4r1c0t/WildCodeSchool/master/Odyssey/Dataset/tweet-sentiment-extraction/train.csv\"\n","url_test = \"https://raw.githubusercontent.com/h4r1c0t/WildCodeSchool/master/Odyssey/Dataset/tweet-sentiment-extraction/test.csv\"\n","\n","df_train = pd.read_csv(url_train)\n","df_test = pd.read_csv(url_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1_jiSJ-IAE90","colab_type":"text"},"source":["## Mission 2 ✔\n","Lis les jeux de données train et test dans Python avec pandas. Conserve uniquement les tweets positifs et négatifs (donc tu exclues les \"neutrals\"). Quel est le pourcentage de tweets positifs/négatifs dans le jeu d'entrainement ? Conserve uniquement les colonnes \"text\" et \"sentiment\" des 2 datasets.\n","\n"]},{"cell_type":"code","metadata":{"id":"JzwZ_rrhJ9OF","colab_type":"code","outputId":"7595d0fe-c0c7-46da-febf-61cee041b074","executionInfo":{"status":"ok","timestamp":1591804439085,"user_tz":-120,"elapsed":3817,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["df_train.info()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 27481 entries, 0 to 27480\n","Data columns (total 4 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   textID         27481 non-null  object\n"," 1   text           27480 non-null  object\n"," 2   selected_text  27480 non-null  object\n"," 3   sentiment      27481 non-null  object\n","dtypes: object(4)\n","memory usage: 858.9+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k8M_IbbSKDqq","colab_type":"code","outputId":"442bbe5c-bbfb-4a05-b120-ff6b63668bbe","executionInfo":{"status":"ok","timestamp":1591804439086,"user_tz":-120,"elapsed":3793,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"source":["df_train.describe(include='all').T"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>unique</th>\n","      <th>top</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>textID</th>\n","      <td>27481</td>\n","      <td>27481</td>\n","      <td>20251532a7</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>text</th>\n","      <td>27480</td>\n","      <td>27480</td>\n","      <td>_addict yeah like super short  I guess I`ll ju...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>selected_text</th>\n","      <td>27480</td>\n","      <td>22463</td>\n","      <td>good</td>\n","      <td>199</td>\n","    </tr>\n","    <tr>\n","      <th>sentiment</th>\n","      <td>27481</td>\n","      <td>3</td>\n","      <td>neutral</td>\n","      <td>11118</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               count  ...   freq\n","textID         27481  ...      1\n","text           27480  ...      1\n","selected_text  27480  ...    199\n","sentiment      27481  ...  11118\n","\n","[4 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"hr3uevDRKJXM","colab_type":"code","outputId":"db48a9c3-cde6-4a78-bc94-f94f2f26293f","executionInfo":{"status":"ok","timestamp":1591804439087,"user_tz":-120,"elapsed":3768,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":194}},"source":["df_test.info()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 3534 entries, 0 to 3533\n","Data columns (total 3 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   textID     3534 non-null   object\n"," 1   text       3534 non-null   object\n"," 2   sentiment  3534 non-null   object\n","dtypes: object(3)\n","memory usage: 83.0+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LAQ8MxdrKN6I","colab_type":"code","outputId":"4326b6e7-fd22-4df7-eeb1-79fa8e0e067a","executionInfo":{"status":"ok","timestamp":1591804439087,"user_tz":-120,"elapsed":3748,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":137}},"source":["df_test.describe(include='all').T"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>unique</th>\n","      <th>top</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>textID</th>\n","      <td>3534</td>\n","      <td>3534</td>\n","      <td>ab464f70e6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>text</th>\n","      <td>3534</td>\n","      <td>3534</td>\n","      <td>someone`s a sweet tooth  i was dying for some...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>sentiment</th>\n","      <td>3534</td>\n","      <td>3</td>\n","      <td>neutral</td>\n","      <td>1430</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          count unique                                                top  freq\n","textID     3534   3534                                         ab464f70e6     1\n","text       3534   3534   someone`s a sweet tooth  i was dying for some...     1\n","sentiment  3534      3                                            neutral  1430"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"k0onjN6mKRbI","colab_type":"text"},"source":["On retire les tweets neutres"]},{"cell_type":"code","metadata":{"id":"TfNZhleqKQw8","colab_type":"code","colab":{}},"source":["df_train_emo = df_train[['text', 'sentiment']][df_train['sentiment'] != 'neutral']\n","\n","df_test_emo = df_test[['text', 'sentiment']][df_test['sentiment'] != 'neutral']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ce3A5CxXKqY7","colab_type":"code","outputId":"608d359c-834b-4af6-c60b-c21089977739","executionInfo":{"status":"ok","timestamp":1591804439088,"user_tz":-120,"elapsed":3718,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["df_train_emo.describe(include='all').T"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>unique</th>\n","      <th>top</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>text</th>\n","      <td>16363</td>\n","      <td>16363</td>\n","      <td>still no pool key. wth. it`s even hot out today.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>sentiment</th>\n","      <td>16363</td>\n","      <td>2</td>\n","      <td>positive</td>\n","      <td>8582</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           count unique                                               top  freq\n","text       16363  16363  still no pool key. wth. it`s even hot out today.     1\n","sentiment  16363      2                                          positive  8582"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"WJIadj0cLaPN","colab_type":"code","outputId":"93fd8c9d-43aa-4d32-a718-c28718655c9a","executionInfo":{"status":"ok","timestamp":1591804439089,"user_tz":-120,"elapsed":3698,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('% de tweets positifs =',\n","      round(len(df_train_emo[df_train_emo['sentiment'] == 'positive']) / df_train_emo.shape[0] * 100, 2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["% de tweets positifs = 52.45\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jmnjTGYXKtcb","colab_type":"code","outputId":"cf613426-a849-47d2-97c2-ebb6636ae67d","executionInfo":{"status":"ok","timestamp":1591804439089,"user_tz":-120,"elapsed":3685,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["df_test_emo.describe(include='all').T"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>unique</th>\n","      <th>top</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>text</th>\n","      <td>2104</td>\n","      <td>2104</td>\n","      <td>someone`s a sweet tooth  i was dying for some...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>sentiment</th>\n","      <td>2104</td>\n","      <td>2</td>\n","      <td>positive</td>\n","      <td>1103</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          count unique                                                top  freq\n","text       2104   2104   someone`s a sweet tooth  i was dying for some...     1\n","sentiment  2104      2                                           positive  1103"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"ZNMS3jL4LxH8","colab_type":"code","outputId":"8ed89f1e-c540-4dfb-baeb-631a1afb1cf5","executionInfo":{"status":"ok","timestamp":1591804439090,"user_tz":-120,"elapsed":3670,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('% de tweets positifs =',\n","      round(len(df_test_emo[df_test_emo['sentiment'] == 'positive']) / df_test_emo.shape[0] * 100, 2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["% de tweets positifs = 52.42\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MMUkpJDNAHSB","colab_type":"text"},"source":["## Mission 3 & 4 ✔\n","Enlève les stop words et utilise un stemmer ou un lemmatizer pour affiner le corpus.\n","\n"]},{"cell_type":"code","metadata":{"id":"DWTKT-9nHj1Q","colab_type":"code","outputId":"cabec145-a4f1-42b7-ddfa-25c7644a6123","executionInfo":{"status":"ok","timestamp":1591804439090,"user_tz":-120,"elapsed":3650,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":406}},"source":["df_train_emo"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2am feedings for the baby are fun when he is a...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27475</th>\n","      <td>enjoy ur night</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27476</th>\n","      <td>wish we could come see u on Denver  husband l...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27477</th>\n","      <td>I`ve wondered about rake to.  The client has ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27478</th>\n","      <td>Yay good for both of you. Enjoy the break - y...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27479</th>\n","      <td>But it was worth it  ****.</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>16363 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment\n","1          Sooo SAD I will miss you here in San Diego!!!  negative\n","2                              my boss is bullying me...  negative\n","3                         what interview! leave me alone  negative\n","4       Sons of ****, why couldn`t they put them on t...  negative\n","6      2am feedings for the baby are fun when he is a...  positive\n","...                                                  ...       ...\n","27475                                     enjoy ur night  positive\n","27476   wish we could come see u on Denver  husband l...  negative\n","27477   I`ve wondered about rake to.  The client has ...  negative\n","27478   Yay good for both of you. Enjoy the break - y...  positive\n","27479                         But it was worth it  ****.  positive\n","\n","[16363 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"VuawKOZQMRXF","colab_type":"code","colab":{}},"source":["def WordsPreprocessing(data):\n","  # Filtre punctuation\n","  pattern = r\"[^\\w]\"\n","  data['text_filtred'] = data['text'].apply(lambda x: re.sub(pattern, \" \", x).lower())\n","\n","  # Tokenization\n","  data['words'] = data['text_filtred'].apply(lambda x: word_tokenize(x))  \n","\n","  stop_words = set(stopwords.words(\"english\"))\n","  lem = WordNetLemmatizer()\n","\n","  for row in range(data.shape[0]):\n","    words = data.iloc[row, 3] # On prend les mots qui correspondent au tweet\n","    filtred_words = []\n","    for w in words:\n","      if not w in stop_words:   # Stopwords\n","        filtred_words.append(lem.lemmatize(w))  # Lemmanization\n","\n","    data.iloc[row, 3] = filtred_words # On remplace la liste de mots par les mots filtrés.\n","    txt=''\n","    for w in filtred_words:       # On refait une phrase avec les mots.\n","      txt += w + ' '\n","    txt = txt.strip()\n","    data.iloc[row, 2] = txt\n","    \n","    data.rename(columns={\"words\": \"words_filtred\"})\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gzqoBgiv5aEm","colab_type":"code","colab":{}},"source":["WordsPreprocessing(df_train_emo)\n","\n","WordsPreprocessing(df_test_emo)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1aNiCOw6LZmi","colab_type":"code","outputId":"ae2a6d06-894d-4b24-d4b1-301c69dcf1fc","executionInfo":{"status":"ok","timestamp":1591804624679,"user_tz":-120,"elapsed":705,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["df_train_emo.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>text_filtred</th>\n","      <th>words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>negative</td>\n","      <td>sooo sad miss san diego</td>\n","      <td>[sooo, sad, miss, san, diego]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","      <td>bos bullying</td>\n","      <td>[bos, bullying]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","      <td>interview leave alone</td>\n","      <td>[interview, leave, alone]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","      <td>son put release already bought</td>\n","      <td>[son, put, release, already, bought]</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2am feedings for the baby are fun when he is a...</td>\n","      <td>positive</td>\n","      <td>2am feeding baby fun smile coo</td>\n","      <td>[2am, feeding, baby, fun, smile, coo]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  ...                                  words\n","1      Sooo SAD I will miss you here in San Diego!!!  ...          [sooo, sad, miss, san, diego]\n","2                          my boss is bullying me...  ...                        [bos, bullying]\n","3                     what interview! leave me alone  ...              [interview, leave, alone]\n","4   Sons of ****, why couldn`t they put them on t...  ...   [son, put, release, already, bought]\n","6  2am feedings for the baby are fun when he is a...  ...  [2am, feeding, baby, fun, smile, coo]\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"UVYua2A1LbPS","colab_type":"code","outputId":"c95068c8-1ab6-425d-fe8d-95b2b0840b84","executionInfo":{"status":"ok","timestamp":1591804625264,"user_tz":-120,"elapsed":665,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["df_test_emo.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>text_filtred</th>\n","      <th>words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Shanghai is also really exciting (precisely -...</td>\n","      <td>positive</td>\n","      <td>shanghai also really exciting precisely skyscr...</td>\n","      <td>[shanghai, also, really, exciting, precisely, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Recession hit Veronique Branquinho, she has to...</td>\n","      <td>negative</td>\n","      <td>recession hit veronique branquinho quit compan...</td>\n","      <td>[recession, hit, veronique, branquinho, quit, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>happy bday!</td>\n","      <td>positive</td>\n","      <td>happy bday</td>\n","      <td>[happy, bday]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>http://twitpic.com/4w75p - I like it!!</td>\n","      <td>positive</td>\n","      <td>http twitpic com 4w75p like</td>\n","      <td>[http, twitpic, com, 4w75p, like]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>that`s great!! weee!! visitors!</td>\n","      <td>positive</td>\n","      <td>great weee visitor</td>\n","      <td>[great, weee, visitor]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  ...                                              words\n","1   Shanghai is also really exciting (precisely -...  ...  [shanghai, also, really, exciting, precisely, ...\n","2  Recession hit Veronique Branquinho, she has to...  ...  [recession, hit, veronique, branquinho, quit, ...\n","3                                        happy bday!  ...                                      [happy, bday]\n","4             http://twitpic.com/4w75p - I like it!!  ...                  [http, twitpic, com, 4w75p, like]\n","5                    that`s great!! weee!! visitors!  ...                             [great, weee, visitor]\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"LV-JwAN8AKVb","colab_type":"text"},"source":["## Mission 5 ✔\n","Crée des features en utilisant scikit-learn (à toi de choisir combien tu en prends et pourquoi) en utilisant la méthode Countvectorizer ou TfidfVectorizer.\n","\n"]},{"cell_type":"code","metadata":{"id":"cvz3XsMQKEbM","colab_type":"code","colab":{}},"source":["# Countvectorizer\n","def count_vectorizer(data):\n","  # Design the Vocabulary\n","  count_vectorizer = CountVectorizer()\n","  # Create the Bag-of-Words Model\n","  bag_of_words = count_vectorizer.fit_transform(data['text_filtred'])\n","  # # Show the Bag-of-Words Model as a pandas DataFrame\n","  # feature_names = count_vectorizer.get_feature_names()\n","  return bag_of_words.toarray()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Fd0c3z2LG8x","colab_type":"code","outputId":"af803654-174d-4072-ae59-0d19557829ba","executionInfo":{"status":"error","timestamp":1591804666947,"user_tz":-120,"elapsed":2352,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["df_train_emo_BoW = count_vectorizer(df_train_emo)\n","df_train_emo_BoW.head()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-3ad39f12708d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_train_emo_BoW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_emo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_train_emo_BoW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"]}]},{"cell_type":"code","metadata":{"id":"qLJVK3iH-j0u","colab_type":"code","colab":{}},"source":["df_test_emo_BoW = count_vectorizer(df_test_emo)\n","df_test_emo_BoW.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOUFa8_89g7o","colab_type":"code","colab":{}},"source":["def VectorWordsFreqCounter(data, threshold):\n","  '''\n","  Permet de compter la fréquence d'apparition et de garder un certain % de la \n","  fréq cumulée et retourne une liste avec les mots à conserver.\n","  '''\n","\n","  counter = pd.DataFrame(data.sum(), columns=['count'])\n","  counter.sort_values('count', ascending = False, inplace = True)\n","\n","  counter['freq'] = counter['count'].apply(lambda x: x/counter['count'].sum())\n","\n","  freq_cum = 0\n","  row = 0\n","\n","  while freq_cum <= threshold:\n","    freq_cum += counter.iloc[row, 1]\n","    row += 1\n","\n","  bag = counter.iloc[:row, :].T\n","\n","  return bag.columns\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gt1_GcLUNLkk","colab_type":"code","outputId":"d553baf2-bc74-4829-9651-b07ac8b1a848","executionInfo":{"status":"error","timestamp":1591804673433,"user_tz":-120,"elapsed":715,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["# df_train_emo_BoW[VectorWordsFreqCounter(df_train_emo_BoW, .90)]"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-e757c756183d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train_emo_BoW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVectorWordsFreqCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_emo_BoW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-35-34f83dc0c9c2>\u001b[0m in \u001b[0;36mVectorWordsFreqCounter\u001b[0;34m(data, threshold)\u001b[0m\n\u001b[1;32m      5\u001b[0m   '''\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    507\u001b[0m                 )\n\u001b[1;32m    508\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"]}]},{"cell_type":"code","metadata":{"id":"-El5Cs_iUHiQ","colab_type":"code","colab":{}},"source":["# df_test_emo_BoW[VectorWordsFreqCounter(df_test_emo_BoW, .90)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iuu7I0ZNKIh8","colab_type":"code","colab":{}},"source":["# TF-IDF Vextorizer\n","def TFIDF_vectorizer(data):\n","  tfidf_vectorizer = TfidfVectorizer()\n","  values = tfidf_vectorizer.fit_transform(data)\n","\n","  # Show the Model as a pandas DataFrame\n","  feature_names = tfidf_vectorizer.get_feature_names()\n","  return values.toarray()\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fu4EvITsVsqt","colab_type":"code","colab":{}},"source":["df_train_emo_tfidf = TFIDF_vectorizer(df_train_emo['text_filtred'])\n","# df_train_emo_tfidf[VectorWordsFreqCounter(df_train_emo_tfidf, .90)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzp4GaZMVo9V","colab_type":"code","colab":{}},"source":["df_test_emo_tfidf = TFIDF_vectorizer(df_test_emo['text_filtred'])\n","# df_test_emo_tfidf[VectorWordsFreqCounter(df_test_emo_tfidf, .90)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8L0l_SMRAL73","colab_type":"text"},"source":["## Mission 6 & 7 ✔\n","En utilisant les features obtenus à l'étape 5 en tant qu'input, entraîne une régression logistique pour classifier les tweets.\n","\n","Mesure la performance (via accuracy_score) de ton algorithme.\n","\n"]},{"cell_type":"code","metadata":{"id":"q1vbYFsDgL-2","colab_type":"code","colab":{}},"source":["# Training a LogReg model\n","def LogRegModeling(data_X, data_y):\n","  X_train = data_X\n","  y_train = data_y['sentiment']\n","\n","  LogisticModel = LogisticRegression().fit(X_train, y_train)\n","\n","  print(\"Model accuracy score =\", LogisticModel.score(X_train, y_train))\n","\n","  return LogisticModel"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SgJmIW5xigoU","colab_type":"code","outputId":"fa0a1964-bd17-437e-d1dd-4d6ebf83df47","executionInfo":{"status":"ok","timestamp":1591804732073,"user_tz":-120,"elapsed":36551,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["LogisticModel_countv = LogRegModeling(df_train_emo_BoW, df_train_emo)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model accuracy score = 0.9537982032634602\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rLclDjDMig8Q","colab_type":"code","outputId":"3ded5edd-3655-434e-96c5-76eaefd7a4a2","executionInfo":{"status":"ok","timestamp":1591804743754,"user_tz":-120,"elapsed":47592,"user":{"displayName":"Sébastien Vanstavel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5NfGIDvXc-vdIHXhbJ3ezTYoxOfaUGnMRSECx5w=s64","userId":"10084807894626874113"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["LogisticModel_tfidf = LogRegModeling(df_train_emo_tfidf, df_train_emo)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model accuracy score = 0.9268471551671454\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q3hKSfivAOnz","colab_type":"text"},"source":["## Mission 8 ✔\n","Teste le modèle avec CountVectorizer et avec TfidfVectorizer. Quelle méthode de preprocessing te permet d'obtenir les résultats les plus performants sur le jeu de test ?\n","\n","> Dans cet exemple, notre model obtient un meilleur score avec la méthode  **CountVectorizer**\n",">\n",">\n",">> ***CountVectorizer*** *accuracy score* : 95.4%\n",">>\n",">>***TfidfVectorizer*** *accuracy score* : 92.7%"]}]}